<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>AWS Certified Architect - Associate_ Udemy</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous"></link>
    <link rel="stylesheet" href="../css/styles.css">
    <style media="screen">

      h3,h4{
        padding-left: 10px;
      }
      h4{
        padding-left: 20px;
      }

      ul{
        list-style-type: disc;
        padding-left: 80px;
      }

      li{
        padding-top: 10px;
      }
  </style>
  </head>
  <body>
    <a class="btn_back" href="../index.html">Back</a><a class="btn_home" href="../index.html">Home</a>
    <h1>AWS Certified Architect - Associate  (Udemy)</h1>

    <div class="">
      <h3>Chapters:</h3>
      <ol>
        <li><a href="#section1">Introduction</a></li>
        <li><a href="#section2">Identity Access Management & S3</a></li>
        <li><a href="#section3">Elastic Cloud Compute</a></li>
        <li><a href="#section4">Databases</a></li>
        <li><a href="#section5">Advanced IAM</a></li>

      </ol>
    </div>

    <div id="section1">
      <h3>1. Introduction</h3>
      <ul>
        <li>
          Invention requires two things <br>
          1. The ability to try alot of experiments, and  <br>
          2. not having to live with the collateral damage of failed experiments. <br>
          -- Andy Jassy (CEO Amazon Webservices)
        </li>
        <li>Think of Availability Zone as a Data Center. A Data Centre is just a building filled with Servers. An Availability be several data centres but because they are closer together, they are counted as one Availability Zone.</li>
        <li>A Region is a geographical area. Each Region consists of 2 (or more) Availability Zones. </li>
        <li>Edge locations are endpoints for AWS which are used for caching content. Typically this consists of CloudFront, Amazon's Content Delivery Network (CDN), There are many more edge locations than Regions.</li>
      </ul>
    </div>

    <div id="section2">
      <h3>2. Identity Access Management & S3</h3>
      <h4>Identy Access Management</h4>
      <ul>
        <li>IAM allows you to manage user and their level of access to the AWS Console.</li>
        <li>It is important to understand IAM for adminstrating a company's AWS account in real life.</li>
        <li>
          IAM offers following features: <br>
          - Centralised control of your AWS account <br>
          - Shared access to your AWS account <br>
          - Granular permissions  <br>
          - Identity Federation (including Active Directory, Facebook, Linkedin etc) <br>
          - Multifactor Authentication <br>
          - Provide temporary access to users/devices and services where necessary <br>
          - Allows you to set up your own password rotation policy. <br>
          - Integrates with many different AWS services <br>
          - Supports PCI DSS compliance.
        </li>
        <li>
          Key terminology for IAM <br>
          - Users : End User such as people, employees of organization etc. <br>
          - Groups : A collection of users. Each user in the group will inherit the permission of the group. <br>
          - Policies : Policies are made up of documents, called Policy documents. These docuemnts are in a format called JSON and they give permissions as to what a User/Group/Role is able to do. <br>
          - Roles : You create roles and assign them to AWS Resources.
        </li>
        <li>IAM is universal. It does not apply to regions at this time.</li>
        <li>The "root account" is simply the account created when first setup your AWS account. It has complete admin access.</li>
        <li>New users have No permissions when first created.</li>
        <li>New users are assigned Accesss Key ID & Secret Access Keys when first created.</li>
        <li>These are not the same as a password. You can not use Accesss Key ID & Secret Access Key to Login in to the console. You can use this to access AWS via APIs and Command Line, However</li>
        <li>You only get to view these once. if you lose them, you have to regenerate them. So, save them in a secured location.</li>
        <li>Always setup Multifactor Authentication on your root account. </li>
        <li>You can create and customize your own password rotation policies.</li>
      </ul>

      <h4>S3</h4>
      <ul>
        <li>Remember that S3 is Object-based: i.e allows you to upload files.</li>
        <li>Files can be from 0 bytes to 5 TB.</li>
        <li>There is unlimited storage.</li>
        <li>Files are stored in Buckets.</li>
        <li>S3 is a universal namespace. That is names must be unique globally.</li>
        <li>URL looks like https://s3-eu-west-1.amazonaws.com/rkbucket</li>
        <li>Not suitable to install an operating system on.</li>
        <li>Successful uploads generate a HTTP 200 status code.</li>
        <li>
          By default, all newly created buckets are PRIVATE. You can setup access contol to your buckets Using <br>
          - Bucket policies <br>
          - Access Control Lists
        </li>
        <li>S3 buckets can be configured to create access logs which logs all requests made to the S3 bucket. This can be sent to another bucket and even another bucket in another account.</li>
        <li>
          The Key fundamentals of S3 are: <br>
          - Key (This is simply the name of the object) <br>
          - Value (This is simply the data and is made up of sequence of bytes). <br>
          - Version ID (Important for versioning). <br>
          - Metadata (Data about data you are storing) <br>
          - Subresources: Access Control Lists , Torenet
        </li>
        <li>Read after Write consistency for PUTs of new Objects</li>
        <li>Eventual Consistency for overwrite PUTs and DELETEs (can take some time to propagate)</li>
        <li>
          S3 Classes of Storage: <br>
          1. S3 Standard : 99.99% availability. 99.999999999% durablility, stored redundantly across multiple devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrelty. <br>
          2. S3 - IA (Infrequently Accessed): For data that is accessed less frequently, but requires rapid access when needed. Lower fee than S3, but you are charged a retrieval fee. <br>
          3. S3 One Zone - IA : For where you want a lower-cost option for Infrequently accessed data, but do not require the multiple Availbility Zone and data resilience. <br>
          4. S3 - Intelligent Tiering : Designed to optimize costs by automatically moving data to the most cost-efffective access tier, without performance impact or operational overhead. <br>
          5. S3 Glacier : is a secure, durable, and low cost storage class for data archiving. Retrieval times configurable from minutes to hours. <br>
          6. S3 Glacier Deep Archive : is Amazon S3's low cost storage class where a retrieval time of 12 hours is acceptable.
        </li>
        <li>Encyption in Transit is achieved by : SSL/TLS</li>
        <li>
          Encryption At Rest (Server Side) is achieved by  <br>
          - S3 Managed Keys - SSE-S3 <br>
          - AWS Key Managements Service / Managed Keys - SSE-KMS <br>
          - Service Side Encryption With Customer Provided Keys - SSE-C
        </li>
        <li>Client Side Encryptoin</li>
        <li>Use S3 Object Locks to store objects using a write once, read many (WORM) model.</li>
        <li>Object locks can be on individual objects or applied across the bucket as a whole.</li>
        <li>
          Object locks come in two modes : governance mode and compliance mode. <br>
          - With governance mode, users can't overwrite or delete an object version or alter its lock settings unless they have special permissions. <br>
          - With compliance mode, a protected object version can't be overwriten or deleted by any user, including the root user in your AWS account.
        </li>
        <li>
          S3 Glacier Vault Lock allows you to easily deploy and enforce compliance controls for individual S3 Glacier vaults with Vault Lock policy.  <br>
          You can specify controls such as WORM in Vault Lock policy and lock the policy from future edits. Once locked, the policy can no longer be changed.
        </li>
        <li><i>mybucketname/folder1/subfolder1/myfile.jpg</i>, in this folder1/subfolder1 is called as prefix</li>
        <li>You can also achieve a high number of requests : 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD </li>
        <li>
          If you are using SSE-KMS to encrypt your objects in S3, you must keep in mind the KMS limits.
          - Uploading/downloading will count toward the KMS quota. <br>
          - Region-specific, however, it's either 5,500 or 10,000 or 30,000 requests per second. <br>
          - Currently, you cannot request quota increase for KMS.
        </li>
        <li>Use multipart uploads to increase performance when uploading files to S3. Should be used for any files over 100 MB and must be used for any file over 5 GB.</li>
        <li>Use S3 byte-range fetches to increase performance when downloading to S3.</li>
        <li>Remember that S3 select used to retrieve only a subset of data from an object by using simple SQL expression.</li>
        <li>Get data by rows or colums using simple SQL expressions.</li>
        <li>Save money on data transfer and increase speed.</li>
        <li>
          Some Best practices with AWS Organization: <br>
          - Always enable multi-factor authentication on root account. <br>
          - Always use a strong and complex password on root account <br>
          - Paying account should be used for billing purposes only. Do not deploy resources in the paying account. <br>
          - Enable/Disable AWS services using Service Control Policies (SCP) either on Organizational Units (OU) or on individual accounts.
        </li>
        <li>
          3 different ways to share S3 bucket across accounts. <br>
          - Using Bucket Policies & IAM (applies across the entire bucket) Programmatic Access Only.
          - Using Bucket ACLs & IAM (individual objects). Programmatic Access Only.
          - Cross-account IAM Roles. Programmatic and Console access.
        </li>
        <li>
          Cross Region Replication <br>
          - Versioning must be enabled on both source and destination buckets. <br>
          - Files in an existing bucket are not replicated automatically. <br>
          - All subsequent updated files will be replicated automatically. <br>
          - Delete markers are not replicated. <br>
          - Deleting individual vesions and delete markers will not be replicated. <br>
        </li>

        <li>
          Lifecycle Policies <br>
          - Automates moving your objects between the different storage tiers. <br>
          - Can be used in conjunction with versioning. <br>
          - Can be applied to current versions and previous versions
        </li>
        <li>S3 Transfer Acceleratation helps to improve speed of file tranfers from edge locations to S3 bucket, which improves the performace of file upload.</li>

      </ul>
    </div>

    <h4>Cloud Front</h4>
    <ul>
      <li>Edge Location : This is the locaiton where content will be cached. This is seperate to AWS Region/AZ.</li>
      <li>Origin : This is origin of all the files that the CDN will distribute. This can be either S3 Bucket, an EC2 Instance, an Elasitc Load Balancer, or Route53. </li>
      <li>Distribution: This is the name given the CDN which consists of a collection of Edge Locations.</li>
      <li>
        Two types of distributions <br>
        1. Web Distribution - Typically used for websites. <br>
        2. RTMP - Used for media streaming
      </li>
      <li>Edge locations are not just READ only -- you can write them too. (i.e put an object on to them)</li>
      <li>Objects are cached for the life of the TTL (Time To Live) </li>
      <li>You can clear cached objects, but you will be charged.</li>
      <li>
        Signed URL <br>
        - Use signed URLs/coockies when you wnat to secure Content so that only the people you authorize are able to access it. <br>
        - A signed URL is for individual files. 1 file = 1 URL. <br>
        - A signed cookie is for multiple files. 1 cookie = multiple files. <br>
        - If your  is EC2, then use CloudFront <br>
      </li>
      <li>
        AWS DataSync <br>
        - Used to move large amounts of data from on-promise to AWS. <br>
        - Used with NFS and SMB compatible file systems. <br>
        - Replication can be done hourly, daily or weekly. <br>
        - Install DataSync agent to start the replication. <br>
        - Can be used to replicate EFS to EFS.
      </li>
      <li>AWS Snowball is used to import data to S3 or export data from S3</li>

      <li>
        Storage Gateway <br>
        - File Gateway : For flat files, stored directly on S3. <br>
        - Volume Gatewys : <br>
         1)Stored Volumes - Entire Dataset is stored on site and is asynchronously backed up to S3. <br>
         2) Cached Volumes - Entire Dataset is stored on S3 and the most frequently accessed data is cached on site. <br>
        - Gateway Virtual Tap Library : Used for backup and uses popular backup applications like NetBackup, Backup Exec, Veeam etc.
      </li>

      <li>
        Athena <br>
        - Athena is an interactive query service. <br>
        - It allows you to query data located in S3 using standard SQL. <br>
        - Serverless <br>
        - Commonly used to analyze log data stored in S3.
      </li>

      <li>
        Macie <br>
        - Uses AI to analyze data in S3 and helps to indentify PII. <br>
        - Can also be used to analyse Cloud Trail logs for suspecious API activity. <br>
        - Includes Datashboards, Reports and Alerting. <br>
        - Greate for PCI-DSS compliance and prevent ID theft.
      </li>

    </ul>

    <div id="section3">
      <h3>3. Elastic Cloud Compute</h3>
      <ul>
        <li>EC2 is a webservice that provides resizable compute capacity in cloud. <br>
            It reduces the time required to obtain and book new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change.
        </li>
        <li>
          Pricing Models <br>
          1. On Demand : Allows you to pay a fixed rate by the hour (or by the second) with no commitment. <br>
          2. Reserved : Provides you with capacity reservation, and offer significant discount on the hourly change for an instance. Contract terms are 1 Year or 3 Year Terms. <br>
          3. Spot : Enables you to bid whatever price you want for instance capacity, providing for even greater savings if your application have flexible start and end times. <br>
          4. Dedicated Hosts : Physical EC2 server dedicated for your use. Dedicated hosts can help you reduce costs by allowing you to use your exisiting server-bound software licenses.
        </li>
        <li>If Spot instance is terminated by Amazon EC2, You will not be charged for the partial hour of usage. However, if you terminate the instance yourself, you will be charged for any hour in which instance ran.</li>
        <li>
          EC2 Instance Types <br>
          F - For FPGA <br>
          I - for IOPS <br>
          G - Graphics <br>
          H - High Disk Thoughhput <br>
          T - Cheap general purpose (Think T2 micro) <br>
          D - For Denisity <br>
          R - for RAM <br>
          M - Main choice for general purpose apps <br>
          C - for Compute <br>
          P - for Graphics (Think Pics) <br>
          X - Extream Memory <br>
          Z - Extream Memory and CPU <br>
          A - Arm based workloads <br>
          U - Bare Metal
        </li>
      </ul>

      <h4>EBS</h4>
      <ul>
        <li>EBS is virtual hard disk drive in the cloud.</li>
        <li>Temination protection is turned off by default, you must turn it on</li>
        <li>On an EBS-backed instance, the default action is for the root EBS volume to be deleted when the instance is terminated.</li>
        <li>EBS root volumes of your DEFAULT AMI's can be encrypted. You can also use a third party tool (such as bit locker etc) to encrypt the root volume, or this can be done when creating AMI's in the AWS console or using API.</li>
        <li>Additional Volumes can be encrypted.</li>
      </ul>

      <h4>Security Groups</h4>
      <ul>
        <li>All inbound traffic is blocked by default.</li>
        <li>All outbound traffic is allowed.</li>
        <li>Changes to Security Groups take effect immedietly.</li>
        <li>You can have any number of EC2 instances within a security group.</li>
        <li>You can have multiple secuity groups attached to EC2 instances</li>
        <li>Security groups are STATEFUL</li>
        <li>If you create an inbound rule allowing traffic in, the traffic is automatically allowed back out again.</li>
        <li>You can not block specific IP addresses using security groups, instead use Network Access Control Lists.</li>
        <li>You can specify allow rules, but not deny rules.</li>
      </ul>
      <h4>EBS Types</h4>
      <table>
        <thead>
          <th></th><th colspan="2">Solid State Drives (SSD)</th><th colspan="3">Hard Disk Drives (HDD)</th>
        </thead>
        <tbody>
          <tr>
            <td>Volume Type</td>
            <td>Generaral Purpose SSD</td>
            <td>Provisioned IOPS SSD</td>
            <td>Throughput Optimized HDD</td>
            <td>Cold HDD</td>
            <td>EBS Magnetic</td>
          </tr>
          <tr>
            <td>Description</td>
            <td>General purpose SSD volume that balances price and performance for a wide variety of transactional workloads.</td>
            <td>Highest-performance SSD volumes designed for missing-critical applications.</td>
            <td>Low cost HDD volume designed for frequently accessed, throughput-intensive workloads.</td>
            <td>Lowest cost HDD volumes designed for less frequently accessed workloads.</td>
            <td>Previous generation HDD</td>
          </tr>
          <tr>
            <td>Use Cases</td>
            <td>Most Work Loads</td>
            <td>Databases</td>
            <td>Big Data & Data Warehouses</td>
            <td>File Servers</td>
            <td>Workloads where data is infrequently accessed</td>
          </tr>
          <tr>
            <td>API Name</td>
            <td>gp2</td>
            <td>io1</td>
            <td>st1</td>
            <td>sc1</td>
            <td>Standard</td>
          </tr>
          <tr>
            <td>Volume Size</td>
            <td>1 Gib - 16 Tib</td>
            <td>4 Gib - 16 Tib</td>
            <td>500 Gib - 16 Tib</td>
            <td>500 Gib - 16 Tib</td>
            <td>1 Gib - 1 Tib</td>
          </tr>
          <tr>
            <td>Max. IOPS/Volume</td>
            <td>16,000</td>
            <td>64,000</td>
            <td>500</td>
            <td>250</td>
            <td>40-200</td>
          </tr>
        </tbody>
      </table>

      <h4>EBS Snapshots</h4>
      <ul>
        <li>Volumes exists on EBS. Think of EBS as a virtual hard disk.</li>
        <li>Snapshots exists on S3. Think of snapshots as photograph of the disk.</li>
        <li>Snapshots are point in time copies of Volumes</li>
        <li>Snapshots are incremental - This means that only the bucket that have changed since your last snapshot are moved to S3.</li>
        <li>If this is your first snapshot, it may take sometime to create.</li>
        <li>To create snapshot for Amazon EBS volumes that serve as root devices, you should stop the instance before taking the snapshot.</li>
        <li>However you can take a snapshot while the instance is running.</li>
        <li>You can create AMI's from both Volumes and Snapshots.</li>
        <li>You can change EBS Volume sizes on the fly, including changing the size and storage type.</li>
        <li>Volumes will ALWAYS be in the same availability zone as the EC2 instance.</li>
      </ul>

      <h4>Migrating EBS</h4>
      <ul>
        <li>To move an EC2 volume from one AZ to another, take a snapshot of it, create an AMI from the snapshot and then use AMI to launch the EC2 instance in a new AZ.</li>
        <li>To move an EC2 instance from on region to another, take a snapshot of it, create an AMI from snapshot and then copy the AMI from one region to another. Then use the copied AMI to launch the new EC2 instance in the new region.</li>
      </ul>

      <h4>EBS Encryption</h4>
      <ul>
        <li>Snapshots of encrypted volumes are encrypted automatically.</li>
        <li>Volumes restored from encrypted snapshots are encrypted automatically.</li>
        <li>You can share snapshots, but only if they are unencrypted.</li>
        <li>These snapshots can be shared with other AWS account or made public.</li>
        <li>
          Root Device Volumes can Now be Encrypted. If you have unencrypted root device volume that needs to encrypted do the following <br>
          - Create a snapshot of unencrypted root device volume. <br>
          - Create a copy of the snapshot and select the encrypt option. <br>
          - Create an AMI from the encrypted snapshot. <br>
          - Use that AMI to launch new encrypted instances.
        </li>
      </ul>

      <h4>EBS Vs Instance Store</h4>
      <ul>
        <li>Instance Store volumes are sometimes called Ephermal Storage.</li>
        <li>Instance store volumes cannot be stopped. If the underlying host fails, you will lose your data.</li>
        <li>EBS backed instances can be stopped. You will not lose your data on this instance, if it is stopped.</li>
        <li>You can reboot both, you will not lose your data.</li>
        <li>By default, both ROOT volumes will be deleted on termination. However, with EBS volumes, you can tell AWS to keep the root device volume.</li>
      </ul>

      <h4>Cloud Watch</h4>
      <ul>
        <li>CloudWatch is used for monitoring performance.</li>
        <li>CloudWatch can monitor most of AWS as well as you application that run on AWS.</li>
        <li>CloudWatch with EC2 will monitor events every 5 minutes by default.</li>
        <li>You can have 1 minute intervals by turning on detailed monitoring.</li>
        <li>You can create CloudWatch alarms which triggers notifications.</li>
        <li>CloudWatch is all about performance and CloudTrail is all about auditing.</li>
        <li>
          What can I do with CloudWatch <br>
          - Dashboards : Create awesome datashbords to see what is happening with you AWS environment. <br>
          - Alarms : Allows you to set Alarms that notify you when particular thresholds are hit. <br>
          - Events : CloudWatch events helps you to respond to state changes in your AWS resources. <br>
          - Logs : CloudWatch logs helps you to aggregate, monitor, and store logs.
        </li>
      </ul>

      <h4>Mislaneous Items</h4>
      <ul>
        <b>CLI:</b> <br>
        - You can interact with AWS from anywhere in the world just by using the command line (CLI). <br>
        - You will need to set up access in IAM.
      </ul>

      <ul>
        <b>Roles</b> <br>
        - Roles are more secure than storing your access keys and secret access keys on individual EC2 instances. <br>
        - Roles are easier to manage. <br>
        - Roles can be assigned to an EC2 instance after it is created using both the console & command line. <br>
        - Roles are universal - you can use them in any region.
      </ul>

      <ul>
        <b>Bootstrap scripts</b> <br>
        - Bootstrp scripts run when an EC2 instance first boots. <br>
        - Can be a powerful way of automating software installs and updates.
      </ul>

      <ul>
        <b>Instance Meta Data & User Data</b><br>
        - Used to get information about an instance (such as public ip) <br>
        - curl http://169.254.169.254/latest/meta-data/ <br>
        - curl http://169.254.169.254/latest/user-data/ <br>
      </ul>

      <h4>EFS</h4>
      <ul>
        <li>Supports the Network File System version 4 (NFSv4) protocol.</li>
        <li>You only pay for the storage you use (no pre-provisioning required)</li>
        <li>Can scale up to petabytes.</li>
        <li>Can support thousands of concurrent NFS connections.</li>
        <li>Data is stored across multiple AZ's within a region.</li>
        <li>Read After Write Consistency.</li>
      </ul>

      <h4>EC2 Placement Groups</h4>
      <ul>
        Three types Placement Groups <br>
        <li>
          Clustered Placement Groups <br>
          - Low Network latency / High Network throughput.
        </li>
        <li>
          Spread Placement Groups <br>
          - Individual Critical EC2 instances
        </li>
        <li>
          Partitioned <br>
          - Multiple EC2 instances HDFS, HBase, and Cassandra
        </li>
        <li>A clustered placement group can't span multiple Availbility Zones, where as Spread placement and Partitioned can.</li>
        <li>The name you specify for placement group must be unique within AWS account.</li>
        <li>Only certain types of instances can be launched in a placement group (Compute Optimized, GPU, Memory Optimized, Storage Optimized)</li>
        <li>AWS recommended homogeneous instances within clusterd placement groups.</li>
        <li>You can't merge placement groups.</li>
        <li>You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group.</li>
      </ul>
    </div>

    <div id="section4">
      <h3>4. Databases</h3>

      <ul>
        <li>
          RDS (OLTP): <br>
          - SQL <br>
          - MySQL <br>
          - PostgreSQL <br>
          - Oracle <br>
          - Aurora <br>
          - MariaDB
        </li>
        <li>DynamoDB (NoSQL)</li>
        <li>Redshift (OLAP)</li>
      </ul>

      <h4>Elastic Cache</h4>
      <ul>
        <li>Memcached  : for simple</li>
        <li>Redis : more advanced data types and for multiple AZs and backups</li>
        <li>Use ElasticCache to increase database and web application performance.</li>
        <li>Redis is Multi-AZ.</li>
        <li>You can do backups and restore of Redis.</li>
        <li>If you need to scale horizantally, use Memcached.</li>
      </ul>

      <ul>
        <li>
          Relational Databases:<br>
          - RDS runs on virtual machines <br>
          - You cannot log in to these operating systems howver. <br>
          - Patching of the RDS Operating System and DB is Amazon's responsibility.  <br>
          - RDS is not serverless <br>
          - Aurora is serverless <br>
        </li>
        <li>
          There are two different types of Backups for RDS: <br>
          - Automated Backups <br>
          - Database snapshots
        </li>
        <li>
          Read Replicas: <br>
          - Can be Multi-AZ. <br>
          - Used to increase performace. <br>
          - Must have backups turned on. <br>
          - Can be in different regions. <br>
          - Can be MySQL, PostgreSQL, MariaDB, Oracle, Aurora <br>
          - Can be promoted to master, this will break the Read Replica
        </li>
        <li>
          - Multi AZ is used for DR (Data Replication) <br>
          - You can force a failover from on AZ to another by rebooting the RDS instance.
        </li>
        <li>
          - Encryption at rest is supported for MySQL, Oracle, SQL Server, PostgreSQL, MariaDB & Aurora. <br>
          - Encryption is done using the AWS Key Management Service (KMS) service. <br>
          - Once you RDS instance is encrypted, the data stored at rest in the underlying storage is encrypted, as are its automated backups, read replicas, and snapshots.
        </li>
      </ul>

      <h4>DynamoDB</h4>
      <ul>
        <li>Stored on SSD storage.</li>
        <li>Spread across 3 geographically distinct data centres.</li>
        <li>Eventual Consistent Reads (Default)</li>
        <li>Strongly Consistent Reads</li>
      </ul>

      <h4>Redshift</h4>
      <ul>
        <li>Redshift is used for business intelligence.</li>
        <li>Available in only 1 AZ.</li>
        <li>Redshift backups enabled for 1 day retention period. Maximum retention period is 35 days.</li>
        <li>Redshift always attempts to maintain at least three copies of your data (the original and replica on compute nodes and a backup in Amazon S3)</li>
        <li>Redshift can also asynchronously replicate your snapshots to S3 in another region for disaster recovery.</li>
      </ul>

      <h4>Aurora</h4>
      <ul>
        <li>2 copies of your data are contained in each availability zone, with minimum of 3 availability zones, 6 copies of your data.</li>
        <li>You can share Aurora Snapshots with other AWS accounts.</li>
        <li>3 types of replicas available. Aurora replicas, MySQL replicas & PostgreSQL replicas.</li>
        <li>Automated failover is only available with Aurora replicas.</li>
        <li>Aurora has automated backups turned on by default. You can take snapshots with Aurora. You can share these snapshots with other AWS accounts.</li>
        <li>Use Aurora Serverless, if you want simple, and cost effective option for infrequent, intermittent, or unpredictable workloads.</li>
      </ul>
    </div>

    <div id="section5">
      <ul>
        <li>
          Directory Service <br>
          - Active Directory <br>
          - Connect AWS resources with on-promises AD <br>
          - SSO to any domain-joined EC2 instance <br>
          - AWS Managed Microsoft AD <br>
          - AD trust <br>
          - AWS vs. customer responsibility
        </li>
        <li>
          - Simple AD <br>
          - Does not support trusts <br>
          - AD connector <br>
          - Cloud Directory <br>
          - Cognito user pools <br>
          - AD and non-AD compatible services
        </li>
        <li>
          IAM Policies <br>
          - ARN  <br>
          - IAM policy structure <br>
          - Effect/Action/Resource <br>
          - Identity vs. Resource policies <br>
          - Policy evaluation logic <br>
          - AWS managed vs. customer managed <br>
          - Permission boudaries <br>
        </li>
        <li>
          Resource Access Manager (RAM) <br>
          - Resource sharing between accounts <br>
          - Individaul accounts and AWS organizations <br>
          - Types of resources you can share
        </li>
        <li>
          Single Sign-On (SSO) <br>
          - Centrally managed access <br>
          - Example: G suite, Office 365, Salesforce <br>
          - Use existing identities. <br>
          - Account level permissions <br>
          - SAML
        </li>
      </ul>
    </div>

    <div id="section6">
      <h2>Route 53</h2>
      <ul>
        <li>ELBs do not have pre-defined IPv4 addresses; you resolve them using a DNS name.</li>
        <li>Understand difference between Alias Record and CNAME</li>
        <li>Given the choice, always choose an Alias Record over CNAME</li>
        <li>
          Common DNS Types : <br>
          - SOA Records <br>
          - NS Records <br>
          - A Records <br>
          - CNAMES <br>
          - MX Records <br>
          - PTR Records
        </li>
        <li>
          The following Routing Polices are avaibale with Route 53: <br>
          - Simple Routing : - If you choose the simple routing policy you can only have one record with multiple IP addresses.
          - if you specify multiple values in a record, Route53 returns all values to user in a random order. <br>
          - Weighted Routing :  used to distribute the percentage of the traffic to the distinations.<br>
          - Latency-based Routing : based on user's location and latency which gets the fast reponse <br>
          - Failover Routing <br>
          - Geolocation Routing <br>
          - Geoproximity Routing (Traffic Flow Only) : routes traffic to your resources based on the geographic location of your users and your resources.
          You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a bias. A bias expands or shrinks the size of the geographic region from which traffic is routed to a resource. To use Geoproximity routing, you must use Route53 traffic flow. <br>
          - Multivalue Answer : Same as Simple based routing, except you get Health checks.
        </li>
        <li>
          Health Checks: <br>
          - You can set health checks on individual record sets. <br>
          - If a record set fails a health check it will be removed from Route53 until it passes the health check. <br>
          - You can set SNS notification to alert you if a health check is failed. <br>
        </li>
      </ul>
    </div>

  </body>
</html>
